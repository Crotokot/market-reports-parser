
<!DOCTYPE html>
<html class="">
	<head>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no" />
		<meta name="description" content="We’re on a journey to advance and democratize artificial intelligence through open source and open science." />
		<meta property="fb:app_id" content="1321688464574422" />
		<meta name="twitter:card" content="summary_large_image" />
		<meta name="twitter:site" content="@huggingface" />
		<meta property="og:title" content="How do Transformers work? - Hugging Face NLP Course" />
		<meta property="og:type" content="website" />
		<meta property="og:url" content="https://huggingface.co/learn/nlp-course/chapter1/4" />
		<meta property="og:image" content="https://huggingface.co/front/thumbnails/learn/nlp-course.png" />

		<link rel="stylesheet" href="/front/build/kube-3d31136/style.css" />

		<link rel="preconnect" href="https://fonts.gstatic.com" />
		<link
			href="https://fonts.googleapis.com/css2?family=Source+Sans+Pro:ital,wght@0,200;0,300;0,400;0,600;0,700;0,900;1,200;1,300;1,400;1,600;1,700;1,900&display=swap"
			rel="stylesheet"
		/>
		<link
			href="https://fonts.googleapis.com/css2?family=IBM+Plex+Mono:wght@400;600;700&display=swap"
			rel="stylesheet"
		/>

		<link
			rel="preload"
			href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css"
			as="style"
			onload="this.onload=null;this.rel='stylesheet'"
		/>
		<noscript>
			<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" />
		</noscript>



		<title>How do Transformers work? - Hugging Face NLP Course</title>

		<script defer data-domain="huggingface.co" src="/js/script.js"></script>
	</head>
	<body class="flex flex-col min-h-screen bg-white dark:bg-gray-950 text-black DocBuilderPage">
		<div class="flex min-h-screen flex-col">
	<div class="SVELTE_HYDRATER contents" data-props="{&quot;classNames&quot;:&quot;&quot;,&quot;isWide&quot;:true,&quot;isZh&quot;:false}" data-target="MainHeader"><header class="border-b border-gray-100 "><div class="w-full px-4  flex h-16 items-center"><div class="flex flex-1 items-center"><a class="mr-5 flex flex-none items-center lg:mr-6" href="/"><img alt="Hugging Face's logo" class="w-7 md:mr-2" src="/front/assets/huggingface_logo-noborder.svg">
				<span class="hidden whitespace-nowrap text-lg font-bold md:block">Hugging Face</span></a>
			<div class="relative flex-1 lg:max-w-sm mr-2 sm:mr-4 lg:mr-6"><input autocomplete="off" class="w-full dark:bg-gray-950 pl-8 form-input-alt h-9 pr-3 focus:shadow-xl" name="" placeholder="Search models, datasets, users..."  spellcheck="false" type="text" value="">
	<svg class="absolute left-2.5 text-gray-400 top-1/2 transform -translate-y-1/2" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M30 28.59L22.45 21A11 11 0 1 0 21 22.45L28.59 30zM5 14a9 9 0 1 1 9 9a9 9 0 0 1-9-9z" fill="currentColor"></path></svg>
	</div>
			<div class="flex flex-none items-center justify-center p-0.5 place-self-stretch lg:hidden"><button class="relative z-30 flex h-6 w-8 items-center justify-center" type="button"><svg width="1em" height="1em" viewBox="0 0 10 10" class="text-xl" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" preserveAspectRatio="xMidYMid meet" fill="currentColor"><path fill-rule="evenodd" clip-rule="evenodd" d="M1.65039 2.9999C1.65039 2.8066 1.80709 2.6499 2.00039 2.6499H8.00039C8.19369 2.6499 8.35039 2.8066 8.35039 2.9999C8.35039 3.1932 8.19369 3.3499 8.00039 3.3499H2.00039C1.80709 3.3499 1.65039 3.1932 1.65039 2.9999ZM1.65039 4.9999C1.65039 4.8066 1.80709 4.6499 2.00039 4.6499H8.00039C8.19369 4.6499 8.35039 4.8066 8.35039 4.9999C8.35039 5.1932 8.19369 5.3499 8.00039 5.3499H2.00039C1.80709 5.3499 1.65039 5.1932 1.65039 4.9999ZM2.00039 6.6499C1.80709 6.6499 1.65039 6.8066 1.65039 6.9999C1.65039 7.1932 1.80709 7.3499 2.00039 7.3499H8.00039C8.19369 7.3499 8.35039 7.1932 8.35039 6.9999C8.35039 6.8066 8.19369 6.6499 8.00039 6.6499H2.00039Z"></path></svg>
		</button>

	</div></div>
		<nav aria-label="Main" class="ml-auto hidden lg:block"><ul class="flex items-center space-x-2"><li><a class="group flex items-center px-2 py-0.5 dark:hover:text-gray-400 hover:text-indigo-700" href="/models"><svg class="mr-1.5 text-gray-400 group-hover:text-indigo-500" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 24 24"><path class="uim-quaternary" d="M20.23 7.24L12 12L3.77 7.24a1.98 1.98 0 0 1 .7-.71L11 2.76c.62-.35 1.38-.35 2 0l6.53 3.77c.29.173.531.418.7.71z" opacity=".25" fill="currentColor"></path><path class="uim-tertiary" d="M12 12v9.5a2.09 2.09 0 0 1-.91-.21L4.5 17.48a2.003 2.003 0 0 1-1-1.73v-7.5a2.06 2.06 0 0 1 .27-1.01L12 12z" opacity=".5" fill="currentColor"></path><path class="uim-primary" d="M20.5 8.25v7.5a2.003 2.003 0 0 1-1 1.73l-6.62 3.82c-.275.13-.576.198-.88.2V12l8.23-4.76c.175.308.268.656.27 1.01z" fill="currentColor"></path></svg>
					Models</a>
			</li><li><a class="group flex items-center px-2 py-0.5 dark:hover:text-gray-400 hover:text-red-700" href="/datasets"><svg class="mr-1.5 text-gray-400 group-hover:text-red-500" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 25 25"><ellipse cx="12.5" cy="5" fill="currentColor" fill-opacity="0.25" rx="7.5" ry="2"></ellipse><path d="M12.5 15C16.6421 15 20 14.1046 20 13V20C20 21.1046 16.6421 22 12.5 22C8.35786 22 5 21.1046 5 20V13C5 14.1046 8.35786 15 12.5 15Z" fill="currentColor" opacity="0.5"></path><path d="M12.5 7C16.6421 7 20 6.10457 20 5V11.5C20 12.6046 16.6421 13.5 12.5 13.5C8.35786 13.5 5 12.6046 5 11.5V5C5 6.10457 8.35786 7 12.5 7Z" fill="currentColor" opacity="0.5"></path><path d="M5.23628 12C5.08204 12.1598 5 12.8273 5 13C5 14.1046 8.35786 15 12.5 15C16.6421 15 20 14.1046 20 13C20 12.8273 19.918 12.1598 19.7637 12C18.9311 12.8626 15.9947 13.5 12.5 13.5C9.0053 13.5 6.06886 12.8626 5.23628 12Z" fill="currentColor"></path></svg>
					Datasets</a>
			</li><li><a class="group flex items-center px-2 py-0.5 dark:hover:text-gray-400 hover:text-blue-700" href="/spaces"><svg class="mr-1.5 text-gray-400 group-hover:text-blue-500" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" viewBox="0 0 25 25"><path opacity=".5" d="M6.016 14.674v4.31h4.31v-4.31h-4.31ZM14.674 14.674v4.31h4.31v-4.31h-4.31ZM6.016 6.016v4.31h4.31v-4.31h-4.31Z" fill="currentColor"></path><path opacity=".75" fill-rule="evenodd" clip-rule="evenodd" d="M3 4.914C3 3.857 3.857 3 4.914 3h6.514c.884 0 1.628.6 1.848 1.414a5.171 5.171 0 0 1 7.31 7.31c.815.22 1.414.964 1.414 1.848v6.514A1.914 1.914 0 0 1 20.086 22H4.914A1.914 1.914 0 0 1 3 20.086V4.914Zm3.016 1.102v4.31h4.31v-4.31h-4.31Zm0 12.968v-4.31h4.31v4.31h-4.31Zm8.658 0v-4.31h4.31v4.31h-4.31Zm0-10.813a2.155 2.155 0 1 1 4.31 0 2.155 2.155 0 0 1-4.31 0Z" fill="currentColor"></path><path opacity=".25" d="M16.829 6.016a2.155 2.155 0 1 0 0 4.31 2.155 2.155 0 0 0 0-4.31Z" fill="currentColor"></path></svg>
					Spaces</a>
			</li><li><a class="group flex items-center px-2 py-0.5 dark:hover:text-gray-400 hover:text-yellow-700" href="/docs"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="mr-1.5 text-gray-400 group-hover:text-yellow-500" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path opacity="0.5" d="M20.9022 5.10334L10.8012 10.8791L7.76318 9.11193C8.07741 8.56791 8.5256 8.11332 9.06512 7.7914L15.9336 3.73907C17.0868 3.08811 18.5002 3.26422 19.6534 3.91519L19.3859 3.73911C19.9253 4.06087 20.5879 4.56025 20.9022 5.10334Z" fill="currentColor"></path><path d="M10.7999 10.8792V28.5483C10.2136 28.5475 9.63494 28.4139 9.10745 28.1578C8.5429 27.8312 8.074 27.3621 7.74761 26.7975C7.42122 26.2327 7.24878 25.5923 7.24756 24.9402V10.9908C7.25062 10.3319 7.42358 9.68487 7.74973 9.1123L10.7999 10.8792Z" fill="currentColor" fill-opacity="0.75"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M21.3368 10.8499V6.918C21.3331 6.25959 21.16 5.61234 20.8346 5.03949L10.7971 10.8727L10.8046 10.874L21.3368 10.8499Z" fill="currentColor"></path><path opacity="0.5" d="M21.7937 10.8488L10.7825 10.8741V28.5486L21.7937 28.5234C23.3344 28.5234 24.5835 27.2743 24.5835 25.7335V13.6387C24.5835 12.0979 23.4365 11.1233 21.7937 10.8488Z" fill="currentColor"></path></svg>
					Docs</a>
			</li>
		<li><div class="relative ">
	<button class="px-2 py-0.5 group hover:text-green-700 dark:hover:text-gray-400 flex items-center " type="button">
		<svg class="mr-1.5 text-gray-400 group-hover:text-green-500" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 24 24"><path class="uim-tertiary" d="M19 6H5a3 3 0 0 0-3 3v2.72L8.837 14h6.326L22 11.72V9a3 3 0 0 0-3-3z" opacity=".5" fill="currentColor"></path><path class="uim-primary" d="M10 6V5h4v1h2V5a2.002 2.002 0 0 0-2-2h-4a2.002 2.002 0 0 0-2 2v1h2zm-1.163 8L2 11.72V18a3.003 3.003 0 0 0 3 3h14a3.003 3.003 0 0 0 3-3v-6.28L15.163 14H8.837z" fill="currentColor"></path></svg>
			Solutions
		</button>



	</div></li>
		<li><a class="group flex items-center px-2 py-0.5 hover:text-gray-500 dark:hover:text-gray-400" href="/pricing">Pricing
			</a></li>

		<li><div class="relative group">
	<button class="px-2 py-0.5 hover:text-gray-500 dark:hover:text-gray-600 flex items-center " type="button">
		<svg class="mr-1.5 text-gray-500 w-5 group-hover:text-gray-400 dark:text-gray-300 dark:group-hover:text-gray-400" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" viewBox="0 0 32 18" preserveAspectRatio="xMidYMid meet"><path fill-rule="evenodd" clip-rule="evenodd" d="M14.4504 3.30221C14.4504 2.836 14.8284 2.45807 15.2946 2.45807H28.4933C28.9595 2.45807 29.3374 2.836 29.3374 3.30221C29.3374 3.76842 28.9595 4.14635 28.4933 4.14635H15.2946C14.8284 4.14635 14.4504 3.76842 14.4504 3.30221Z" fill="currentColor"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M14.4504 9.00002C14.4504 8.53382 14.8284 8.15588 15.2946 8.15588H28.4933C28.9595 8.15588 29.3374 8.53382 29.3374 9.00002C29.3374 9.46623 28.9595 9.84417 28.4933 9.84417H15.2946C14.8284 9.84417 14.4504 9.46623 14.4504 9.00002Z" fill="currentColor"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M14.4504 14.6978C14.4504 14.2316 14.8284 13.8537 15.2946 13.8537H28.4933C28.9595 13.8537 29.3374 14.2316 29.3374 14.6978C29.3374 15.164 28.9595 15.542 28.4933 15.542H15.2946C14.8284 15.542 14.4504 15.164 14.4504 14.6978Z" fill="currentColor"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M1.94549 6.87377C2.27514 6.54411 2.80962 6.54411 3.13928 6.87377L6.23458 9.96907L9.32988 6.87377C9.65954 6.54411 10.194 6.54411 10.5237 6.87377C10.8533 7.20343 10.8533 7.73791 10.5237 8.06756L6.23458 12.3567L1.94549 8.06756C1.61583 7.73791 1.61583 7.20343 1.94549 6.87377Z" fill="currentColor"></path></svg>

		</button>



	</div></li>
		<li><hr class="h-5 w-0.5 border-none bg-gray-100 dark:bg-gray-800"></li>
		<li><a class="block cursor-pointer px-2 py-0.5 hover:text-gray-500 dark:hover:text-gray-400" href="/login">Log In
				</a></li>
			<li><a class="rounded-full border border-transparent bg-gray-900 px-3 py-1 leading-none text-white hover:border-black hover:bg-white hover:text-black" href="/join">Sign Up
					</a></li></ul></nav></div></header></div>

	<div class="SVELTE_HYDRATER contents" data-props="{}" data-target="GoogleAnalyticsTracker"></div>


	<div class="SVELTE_HYDRATER contents" data-props="{}" data-target="SSOBanner"></div>

	<main class="flex flex-1 flex-col"><div class="relative lg:flex"><div class="sticky top-0 z-20 self-start"><div class="SVELTE_HYDRATER contents" data-props="{&quot;chapters&quot;:[{&quot;title&quot;:&quot;0. Setup&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;Introduction&quot;,&quot;id&quot;:&quot;chapter0/1&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter0/1?fw=pt&quot;}]},{&quot;title&quot;:&quot;1. Transformer models&quot;,&quot;isExpanded&quot;:true,&quot;sections&quot;:[{&quot;title&quot;:&quot;Introduction&quot;,&quot;id&quot;:&quot;chapter1/1&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter1/1?fw=pt&quot;},{&quot;title&quot;:&quot;Natural Language Processing&quot;,&quot;id&quot;:&quot;chapter1/2&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter1/2?fw=pt&quot;},{&quot;title&quot;:&quot;Transformers, what can they do?&quot;,&quot;id&quot;:&quot;chapter1/3&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter1/3?fw=pt&quot;},{&quot;title&quot;:&quot;How do Transformers work?&quot;,&quot;isExpanded&quot;:true,&quot;id&quot;:&quot;chapter1/4&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter1/4?fw=pt&quot;},{&quot;title&quot;:&quot;Encoder models&quot;,&quot;id&quot;:&quot;chapter1/5&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter1/5?fw=pt&quot;},{&quot;title&quot;:&quot;Decoder models&quot;,&quot;id&quot;:&quot;chapter1/6&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter1/6?fw=pt&quot;},{&quot;title&quot;:&quot;Sequence-to-sequence models&quot;,&quot;id&quot;:&quot;chapter1/7&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter1/7?fw=pt&quot;},{&quot;title&quot;:&quot;Bias and limitations&quot;,&quot;id&quot;:&quot;chapter1/8&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter1/8?fw=pt&quot;},{&quot;title&quot;:&quot;Summary&quot;,&quot;id&quot;:&quot;chapter1/9&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter1/9?fw=pt&quot;},{&quot;title&quot;:&quot;End-of-chapter quiz&quot;,&quot;quiz&quot;:1,&quot;id&quot;:&quot;chapter1/10&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter1/10?fw=pt&quot;}]},{&quot;title&quot;:&quot;2. Using 🤗 Transformers&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;Introduction&quot;,&quot;id&quot;:&quot;chapter2/1&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter2/1?fw=pt&quot;},{&quot;title&quot;:&quot;Behind the pipeline&quot;,&quot;id&quot;:&quot;chapter2/2&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter2/2?fw=pt&quot;},{&quot;title&quot;:&quot;Models&quot;,&quot;id&quot;:&quot;chapter2/3&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter2/3?fw=pt&quot;},{&quot;title&quot;:&quot;Tokenizers&quot;,&quot;id&quot;:&quot;chapter2/4&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter2/4?fw=pt&quot;},{&quot;title&quot;:&quot;Handling multiple sequences&quot;,&quot;id&quot;:&quot;chapter2/5&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter2/5?fw=pt&quot;},{&quot;title&quot;:&quot;Putting it all together&quot;,&quot;id&quot;:&quot;chapter2/6&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter2/6?fw=pt&quot;},{&quot;title&quot;:&quot;Basic usage completed!&quot;,&quot;id&quot;:&quot;chapter2/7&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter2/7?fw=pt&quot;},{&quot;title&quot;:&quot;End-of-chapter quiz&quot;,&quot;quiz&quot;:2,&quot;id&quot;:&quot;chapter2/8&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter2/8?fw=pt&quot;}]},{&quot;title&quot;:&quot;3. Fine-tuning a pretrained model&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;Introduction&quot;,&quot;id&quot;:&quot;chapter3/1&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter3/1?fw=pt&quot;},{&quot;title&quot;:&quot;Processing the data&quot;,&quot;id&quot;:&quot;chapter3/2&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter3/2?fw=pt&quot;},{&quot;title&quot;:&quot;Fine-tuning a model with the Trainer API or Keras&quot;,&quot;local_fw&quot;:{&quot;pt&quot;:&quot;chapter3/3&quot;,&quot;tf&quot;:&quot;chapter3/3_tf&quot;},&quot;id&quot;:&quot;chapter3/3&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter3/3?fw=pt&quot;},{&quot;title&quot;:&quot;A full training&quot;,&quot;id&quot;:&quot;chapter3/4&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter3/4?fw=pt&quot;},{&quot;title&quot;:&quot;Fine-tuning, Check!&quot;,&quot;id&quot;:&quot;chapter3/5&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter3/5?fw=pt&quot;},{&quot;title&quot;:&quot;End-of-chapter quiz&quot;,&quot;quiz&quot;:3,&quot;id&quot;:&quot;chapter3/6&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter3/6?fw=pt&quot;}]},{&quot;title&quot;:&quot;4. Sharing models and tokenizers&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;The Hugging Face Hub&quot;,&quot;id&quot;:&quot;chapter4/1&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter4/1?fw=pt&quot;},{&quot;title&quot;:&quot;Using pretrained models&quot;,&quot;id&quot;:&quot;chapter4/2&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter4/2?fw=pt&quot;},{&quot;title&quot;:&quot;Sharing pretrained models&quot;,&quot;id&quot;:&quot;chapter4/3&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter4/3?fw=pt&quot;},{&quot;title&quot;:&quot;Building a model card&quot;,&quot;id&quot;:&quot;chapter4/4&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter4/4?fw=pt&quot;},{&quot;title&quot;:&quot;Part 1 completed!&quot;,&quot;id&quot;:&quot;chapter4/5&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter4/5?fw=pt&quot;},{&quot;title&quot;:&quot;End-of-chapter quiz&quot;,&quot;quiz&quot;:4,&quot;id&quot;:&quot;chapter4/6&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter4/6?fw=pt&quot;}]},{&quot;title&quot;:&quot;5. The 🤗 Datasets library&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;Introduction&quot;,&quot;id&quot;:&quot;chapter5/1&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter5/1?fw=pt&quot;},{&quot;title&quot;:&quot;What if my dataset isn't on the Hub?&quot;,&quot;id&quot;:&quot;chapter5/2&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter5/2?fw=pt&quot;},{&quot;title&quot;:&quot;Time to slice and dice&quot;,&quot;id&quot;:&quot;chapter5/3&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter5/3?fw=pt&quot;},{&quot;title&quot;:&quot;Big data? 🤗 Datasets to the rescue!&quot;,&quot;id&quot;:&quot;chapter5/4&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter5/4?fw=pt&quot;},{&quot;title&quot;:&quot;Creating your own dataset&quot;,&quot;id&quot;:&quot;chapter5/5&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter5/5?fw=pt&quot;},{&quot;title&quot;:&quot;Semantic search with FAISS&quot;,&quot;id&quot;:&quot;chapter5/6&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter5/6?fw=pt&quot;},{&quot;title&quot;:&quot;🤗 Datasets, check!&quot;,&quot;id&quot;:&quot;chapter5/7&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter5/7?fw=pt&quot;},{&quot;title&quot;:&quot;End-of-chapter quiz&quot;,&quot;quiz&quot;:5,&quot;id&quot;:&quot;chapter5/8&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter5/8?fw=pt&quot;}]},{&quot;title&quot;:&quot;6. The 🤗 Tokenizers library&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;Introduction&quot;,&quot;id&quot;:&quot;chapter6/1&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter6/1?fw=pt&quot;},{&quot;title&quot;:&quot;Training a new tokenizer from an old one&quot;,&quot;id&quot;:&quot;chapter6/2&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter6/2?fw=pt&quot;},{&quot;title&quot;:&quot;Fast tokenizers' special powers&quot;,&quot;id&quot;:&quot;chapter6/3&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter6/3?fw=pt&quot;},{&quot;title&quot;:&quot;Fast tokenizers in the QA pipeline&quot;,&quot;id&quot;:&quot;chapter6/3b&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter6/3b?fw=pt&quot;},{&quot;title&quot;:&quot;Normalization and pre-tokenization&quot;,&quot;id&quot;:&quot;chapter6/4&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter6/4?fw=pt&quot;},{&quot;title&quot;:&quot;Byte-Pair Encoding tokenization&quot;,&quot;id&quot;:&quot;chapter6/5&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter6/5?fw=pt&quot;},{&quot;title&quot;:&quot;WordPiece tokenization&quot;,&quot;id&quot;:&quot;chapter6/6&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter6/6?fw=pt&quot;},{&quot;title&quot;:&quot;Unigram tokenization&quot;,&quot;id&quot;:&quot;chapter6/7&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter6/7?fw=pt&quot;},{&quot;title&quot;:&quot;Building a tokenizer, block by block&quot;,&quot;id&quot;:&quot;chapter6/8&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter6/8?fw=pt&quot;},{&quot;title&quot;:&quot;Tokenizers, check!&quot;,&quot;id&quot;:&quot;chapter6/9&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter6/9?fw=pt&quot;},{&quot;title&quot;:&quot;End-of-chapter quiz&quot;,&quot;quiz&quot;:6,&quot;id&quot;:&quot;chapter6/10&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter6/10?fw=pt&quot;}]},{&quot;title&quot;:&quot;7. Main NLP tasks&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;Introduction&quot;,&quot;id&quot;:&quot;chapter7/1&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter7/1?fw=pt&quot;},{&quot;title&quot;:&quot;Token classification&quot;,&quot;id&quot;:&quot;chapter7/2&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter7/2?fw=pt&quot;},{&quot;title&quot;:&quot;Fine-tuning a masked language model&quot;,&quot;id&quot;:&quot;chapter7/3&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter7/3?fw=pt&quot;},{&quot;title&quot;:&quot;Translation&quot;,&quot;id&quot;:&quot;chapter7/4&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter7/4?fw=pt&quot;},{&quot;title&quot;:&quot;Summarization&quot;,&quot;id&quot;:&quot;chapter7/5&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter7/5?fw=pt&quot;},{&quot;title&quot;:&quot;Training a causal language model from scratch&quot;,&quot;id&quot;:&quot;chapter7/6&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter7/6?fw=pt&quot;},{&quot;title&quot;:&quot;Question answering&quot;,&quot;id&quot;:&quot;chapter7/7&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter7/7?fw=pt&quot;},{&quot;title&quot;:&quot;Mastering NLP&quot;,&quot;id&quot;:&quot;chapter7/8&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter7/8?fw=pt&quot;},{&quot;title&quot;:&quot;End-of-chapter quiz&quot;,&quot;quiz&quot;:7,&quot;id&quot;:&quot;chapter7/9&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter7/9?fw=pt&quot;}]},{&quot;title&quot;:&quot;8. How to ask for help&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;Introduction&quot;,&quot;id&quot;:&quot;chapter8/1&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter8/1?fw=pt&quot;},{&quot;title&quot;:&quot;What to do when you get an error&quot;,&quot;id&quot;:&quot;chapter8/2&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter8/2?fw=pt&quot;},{&quot;title&quot;:&quot;Asking for help on the forums&quot;,&quot;id&quot;:&quot;chapter8/3&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter8/3?fw=pt&quot;},{&quot;title&quot;:&quot;Debugging the training pipeline&quot;,&quot;local_fw&quot;:{&quot;pt&quot;:&quot;chapter8/4&quot;,&quot;tf&quot;:&quot;chapter8/4_tf&quot;},&quot;id&quot;:&quot;chapter8/4&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter8/4?fw=pt&quot;},{&quot;title&quot;:&quot;How to write a good issue&quot;,&quot;id&quot;:&quot;chapter8/5&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter8/5?fw=pt&quot;},{&quot;title&quot;:&quot;Part 2 completed!&quot;,&quot;id&quot;:&quot;chapter8/6&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter8/6?fw=pt&quot;},{&quot;title&quot;:&quot;End-of-chapter quiz&quot;,&quot;quiz&quot;:8,&quot;id&quot;:&quot;chapter8/7&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter8/7?fw=pt&quot;}]},{&quot;title&quot;:&quot;9. Building and sharing demos&quot;,&quot;new&quot;:true,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;Introduction to Gradio&quot;,&quot;id&quot;:&quot;chapter9/1&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter9/1?fw=pt&quot;},{&quot;title&quot;:&quot;Building your first demo&quot;,&quot;id&quot;:&quot;chapter9/2&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter9/2?fw=pt&quot;},{&quot;title&quot;:&quot;Understanding the Interface class&quot;,&quot;id&quot;:&quot;chapter9/3&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter9/3?fw=pt&quot;},{&quot;title&quot;:&quot;Sharing demos with others&quot;,&quot;id&quot;:&quot;chapter9/4&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter9/4?fw=pt&quot;},{&quot;title&quot;:&quot;Integrations with the Hugging Face Hub&quot;,&quot;id&quot;:&quot;chapter9/5&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter9/5?fw=pt&quot;},{&quot;title&quot;:&quot;Advanced Interface features&quot;,&quot;id&quot;:&quot;chapter9/6&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter9/6?fw=pt&quot;},{&quot;title&quot;:&quot;Introduction to Blocks&quot;,&quot;id&quot;:&quot;chapter9/7&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter9/7?fw=pt&quot;},{&quot;title&quot;:&quot;Gradio, check!&quot;,&quot;id&quot;:&quot;chapter9/8&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter9/8?fw=pt&quot;},{&quot;title&quot;:&quot;End-of-chapter quiz&quot;,&quot;quiz&quot;:9,&quot;id&quot;:&quot;chapter9/9&quot;,&quot;url&quot;:&quot;/learn/nlp-course/chapter9/9?fw=pt&quot;}]},{&quot;title&quot;:&quot;Course Events&quot;,&quot;isExpanded&quot;:false,&quot;sections&quot;:[{&quot;title&quot;:&quot;Live sessions and workshops&quot;,&quot;id&quot;:&quot;events/1&quot;,&quot;url&quot;:&quot;/learn/nlp-course/events/1?fw=pt&quot;},{&quot;title&quot;:&quot;Part 2 release event&quot;,&quot;id&quot;:&quot;events/2&quot;,&quot;url&quot;:&quot;/learn/nlp-course/events/2?fw=pt&quot;},{&quot;title&quot;:&quot;Gradio Blocks party&quot;,&quot;id&quot;:&quot;events/3&quot;,&quot;url&quot;:&quot;/learn/nlp-course/events/3?fw=pt&quot;}]}],&quot;chapterId&quot;:&quot;chapter1/4&quot;,&quot;docType&quot;:&quot;learn&quot;,&quot;isLoggedIn&quot;:false,&quot;lang&quot;:&quot;en&quot;,&quot;langs&quot;:[&quot;ar&quot;,&quot;bn&quot;,&quot;de&quot;,&quot;en&quot;,&quot;es&quot;,&quot;fa&quot;,&quot;fr&quot;,&quot;gj&quot;,&quot;he&quot;,&quot;hi&quot;,&quot;id&quot;,&quot;it&quot;,&quot;ja&quot;,&quot;ko&quot;,&quot;pt&quot;,&quot;ru&quot;,&quot;th&quot;,&quot;tr&quot;,&quot;vi&quot;,&quot;zh-CN&quot;,&quot;zh-TW&quot;],&quot;library&quot;:&quot;nlp-course&quot;,&quot;theme&quot;:&quot;light&quot;,&quot;version&quot;:&quot;main&quot;,&quot;versions&quot;:[{&quot;version&quot;:&quot;main&quot;}],&quot;title&quot;:&quot;How do Transformers work?&quot;}" data-target="SideMenu">



<div class="z-2 w-full flex-none lg:block lg:h-screen lg:w-[270px] 2xl:w-[300px] false"><div class="shadow-alternate flex h-16 w-full items-center rounded-b-xl border-b bg-white text-lg leading-tight lg:hidden">
		<div class="flex flex-1 cursor-pointer flex-col justify-center self-stretch pl-6"><p class="text-sm text-gray-400 first-letter:capitalize">NLP Course documentation
			</p>
			<div class="flex items-center"><p class="font-semibold">How do Transformers work?</p>
				<svg class="text-xl false" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 24 24"><path d="M16.293 9.293L12 13.586L7.707 9.293l-1.414 1.414L12 16.414l5.707-5.707z" fill="currentColor"></path></svg></div></div>
		<button class="hover:shadow-alternate group ml-auto mr-6 inline-flex flex-none cursor-pointer rounded-xl border p-2"><svg class="text-gray-500 group-hover:text-gray-700" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M30 28.59L22.45 21A11 11 0 1 0 21 22.45L28.59 30zM5 14a9 9 0 1 1 9 9a9 9 0 0 1-9-9z" fill="currentColor"></path></svg></button></div>
	<div class="hidden h-32 flex-col justify-between border-r border-b bg-white bg-gradient-to-r p-4 lg:flex from-amber-50 to-white dark:from-gray-900 dark:to-gray-950" style="background: url(https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/course-logo.png); background-position: 90% 5%; background-repeat: no-repeat; background-size: 18%;"><div class="relative ">
	<button class=" " type="button">

				<h1 class="flex items-center text-lg font-bold leading-tight first-letter:capitalize"><div class="mr-1.5 h-1.5 w-1.5 rounded-full bg-amber-500 flex-none"></div>
					NLP Course
					<span><svg class="opacity-70 " xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 24 24"><path d="M16.293 9.293L12 13.586L7.707 9.293l-1.414 1.414L12 16.414l5.707-5.707z" fill="currentColor"></path></svg></span></h1>

		</button>



	</div>
		<button class="shadow-alternate flex w-full items-center rounded-full border bg-white px-2 py-1 text-left text-sm text-gray-400 ring-indigo-200 hover:bg-indigo-50 hover:ring-2 dark:border-gray-700 dark:ring-yellow-600 dark:hover:bg-gray-900 dark:hover:text-yellow-500"><svg class="flex-none mr-1.5" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M30 28.59L22.45 21A11 11 0 1 0 21 22.45L28.59 30zM5 14a9 9 0 1 1 9 9a9 9 0 0 1-9-9z" fill="currentColor"></path></svg>
			<div>Search documentation</div>
			</button>
		<div class="flex items-center">

			<select class="form-input mr-1 rounded border-gray-200 p-1 text-xs dark:!text-gray-400 !w-12 !mt-0 !border"><option value="ar" >AR</option><option value="bn" >BN</option><option value="de" >DE</option><option value="en" selected>EN</option><option value="es" >ES</option><option value="fa" >FA</option><option value="fr" >FR</option><option value="gj" >GJ</option><option value="he" >HE</option><option value="hi" >HI</option><option value="id" >ID</option><option value="it" >IT</option><option value="ja" >JA</option><option value="ko" >KO</option><option value="pt" >PT</option><option value="ru" >RU</option><option value="th" >TH</option><option value="tr" >TR</option><option value="vi" >VI</option><option value="zh-CN" >ZH-CN</option><option value="zh-TW" >ZH-TW</option></select>

<div class="relative inline-block">
	<button class="rounded-full border border-gray-100 py-1 pl-2 pr-0.5 flex items-center text-sm text-gray-500 bg-white hover:bg-yellow-50 hover:border-yellow-200 dark:hover:bg-gray-800 dark:hover:border-gray-950 " type="button">
		<svg class="mr-1.5 text-yellow-500" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 24 24" fill="currentColor"><path d="M6.05 4.14l-.39-.39a.993.993 0 0 0-1.4 0l-.01.01a.984.984 0 0 0 0 1.4l.39.39c.39.39 1.01.39 1.4 0l.01-.01a.984.984 0 0 0 0-1.4zM3.01 10.5H1.99c-.55 0-.99.44-.99.99v.01c0 .55.44.99.99.99H3c.56.01 1-.43 1-.98v-.01c0-.56-.44-1-.99-1zm9-9.95H12c-.56 0-1 .44-1 .99v.96c0 .55.44.99.99.99H12c.56.01 1-.43 1-.98v-.97c0-.55-.44-.99-.99-.99zm7.74 3.21c-.39-.39-1.02-.39-1.41-.01l-.39.39a.984.984 0 0 0 0 1.4l.01.01c.39.39 1.02.39 1.4 0l.39-.39a.984.984 0 0 0 0-1.4zm-1.81 15.1l.39.39a.996.996 0 1 0 1.41-1.41l-.39-.39a.993.993 0 0 0-1.4 0c-.4.4-.4 1.02-.01 1.41zM20 11.49v.01c0 .55.44.99.99.99H22c.55 0 .99-.44.99-.99v-.01c0-.55-.44-.99-.99-.99h-1.01c-.55 0-.99.44-.99.99zM12 5.5c-3.31 0-6 2.69-6 6s2.69 6 6 6s6-2.69 6-6s-2.69-6-6-6zm-.01 16.95H12c.55 0 .99-.44.99-.99v-.96c0-.55-.44-.99-.99-.99h-.01c-.55 0-.99.44-.99.99v.96c0 .55.44.99.99.99zm-7.74-3.21c.39.39 1.02.39 1.41 0l.39-.39a.993.993 0 0 0 0-1.4l-.01-.01a.996.996 0 0 0-1.41 0l-.39.39c-.38.4-.38 1.02.01 1.41z"></path></svg>

		</button>



	</div>
			<a href="https://github.com/huggingface/course" class="group ml-auto text-xs text-gray-500 hover:text-gray-700 hover:underline dark:hover:text-gray-300"><svg class="inline-block text-gray-500 group-hover:text-gray-700 dark:group-hover:text-gray-300 mr-1.5 -mt-1 w-4 h-4" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1.03em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 250"><path d="M128.001 0C57.317 0 0 57.307 0 128.001c0 56.554 36.676 104.535 87.535 121.46c6.397 1.185 8.746-2.777 8.746-6.158c0-3.052-.12-13.135-.174-23.83c-35.61 7.742-43.124-15.103-43.124-15.103c-5.823-14.795-14.213-18.73-14.213-18.73c-11.613-7.944.876-7.78.876-7.78c12.853.902 19.621 13.19 19.621 13.19c11.417 19.568 29.945 13.911 37.249 10.64c1.149-8.272 4.466-13.92 8.127-17.116c-28.431-3.236-58.318-14.212-58.318-63.258c0-13.975 5-25.394 13.188-34.358c-1.329-3.224-5.71-16.242 1.24-33.874c0 0 10.749-3.44 35.21 13.121c10.21-2.836 21.16-4.258 32.038-4.307c10.878.049 21.837 1.47 32.066 4.307c24.431-16.56 35.165-13.12 35.165-13.12c6.967 17.63 2.584 30.65 1.255 33.873c8.207 8.964 13.173 20.383 13.173 34.358c0 49.163-29.944 59.988-58.447 63.157c4.591 3.972 8.682 11.762 8.682 23.704c0 17.126-.148 30.91-.148 35.126c0 3.407 2.304 7.398 8.792 6.14C219.37 232.5 256 184.537 256 128.002C256 57.307 198.691 0 128.001 0zm-80.06 182.34c-.282.636-1.283.827-2.194.39c-.929-.417-1.45-1.284-1.15-1.922c.276-.655 1.279-.838 2.205-.399c.93.418 1.46 1.293 1.139 1.931zm6.296 5.618c-.61.566-1.804.303-2.614-.591c-.837-.892-.994-2.086-.375-2.66c.63-.566 1.787-.301 2.626.591c.838.903 1 2.088.363 2.66zm4.32 7.188c-.785.545-2.067.034-2.86-1.104c-.784-1.138-.784-2.503.017-3.05c.795-.547 2.058-.055 2.861 1.075c.782 1.157.782 2.522-.019 3.08zm7.304 8.325c-.701.774-2.196.566-3.29-.49c-1.119-1.032-1.43-2.496-.726-3.27c.71-.776 2.213-.558 3.315.49c1.11 1.03 1.45 2.505.701 3.27zm9.442 2.81c-.31 1.003-1.75 1.459-3.199 1.033c-1.448-.439-2.395-1.613-2.103-2.626c.301-1.01 1.747-1.484 3.207-1.028c1.446.436 2.396 1.602 2.095 2.622zm10.744 1.193c.036 1.055-1.193 1.93-2.715 1.95c-1.53.034-2.769-.82-2.786-1.86c0-1.065 1.202-1.932 2.733-1.958c1.522-.03 2.768.818 2.768 1.868zm10.555-.405c.182 1.03-.875 2.088-2.387 2.37c-1.485.271-2.861-.365-3.05-1.386c-.184-1.056.893-2.114 2.376-2.387c1.514-.263 2.868.356 3.061 1.403z" fill="currentColor"></path></svg>
				</a></div></div>

	<nav class="top-32 hidden lg:flex absolute bottom-0 left-0 w-full flex-col overflow-y-auto border-r px-4 pt-3 pb-16 text-[0.95rem] lg:w-[270px] 2xl:w-[300px]">

		<div class="group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0"><div class="flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-['▶'] false"><span><span class="inline-block space-x-1 leading-5"><span><!-- HTML_TAG_START -->0. Setup<!-- HTML_TAG_END --></span>

					</span></span>
			</div></div>

		<div class="group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0"><div class="flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-['▶'] after:rotate-90 after:transform"><span><span class="inline-block space-x-1 leading-5"><span><!-- HTML_TAG_START -->1. Transformer models<!-- HTML_TAG_END --></span>

					</span></span>
			</div></div>
		<div class="flex flex-col"><a class="transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2" href="/learn/nlp-course/chapter1/1?fw=pt"><!-- HTML_TAG_START -->Introduction<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2" href="/learn/nlp-course/chapter1/2?fw=pt"><!-- HTML_TAG_START -->Natural Language Processing<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2" href="/learn/nlp-course/chapter1/3?fw=pt"><!-- HTML_TAG_START -->Transformers, what can they do?<!-- HTML_TAG_END -->
		</a><a class="rounded-xl bg-gradient-to-br from-black to-gray-900 py-1 pr-2 pl-2 text-white first:mt-1 last:mb-4 dark:from-gray-800 dark:to-gray-900 ml-2" href="/learn/nlp-course/chapter1/4?fw=pt"><!-- HTML_TAG_START -->How do Transformers work?<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2" href="/learn/nlp-course/chapter1/5?fw=pt"><!-- HTML_TAG_START -->Encoder models<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2" href="/learn/nlp-course/chapter1/6?fw=pt"><!-- HTML_TAG_START -->Decoder models<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2" href="/learn/nlp-course/chapter1/7?fw=pt"><!-- HTML_TAG_START -->Sequence-to-sequence models<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2" href="/learn/nlp-course/chapter1/8?fw=pt"><!-- HTML_TAG_START -->Bias and limitations<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2" href="/learn/nlp-course/chapter1/9?fw=pt"><!-- HTML_TAG_START -->Summary<!-- HTML_TAG_END -->
		</a><a class="transform py-1 pr-2 pl-2 text-gray-500 first:mt-1 last:mb-4 hover:translate-x-px hover:text-black dark:hover:text-gray-300 ml-2" href="/learn/nlp-course/chapter1/10?fw=pt"><!-- HTML_TAG_START -->End-of-chapter quiz<!-- HTML_TAG_END -->
		</a>
			</div>
		<div class="group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0"><div class="flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-['▶'] false"><span><span class="inline-block space-x-1 leading-5"><span><!-- HTML_TAG_START -->2. Using 🤗 Transformers<!-- HTML_TAG_END --></span>

					</span></span>
			</div></div>

		<div class="group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0"><div class="flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-['▶'] false"><span><span class="inline-block space-x-1 leading-5"><span><!-- HTML_TAG_START -->3. Fine-tuning a pretrained model<!-- HTML_TAG_END --></span>

					</span></span>
			</div></div>

		<div class="group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0"><div class="flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-['▶'] false"><span><span class="inline-block space-x-1 leading-5"><span><!-- HTML_TAG_START -->4. Sharing models and tokenizers<!-- HTML_TAG_END --></span>

					</span></span>
			</div></div>

		<div class="group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0"><div class="flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-['▶'] false"><span><span class="inline-block space-x-1 leading-5"><span><!-- HTML_TAG_START -->5. The 🤗 Datasets library<!-- HTML_TAG_END --></span>

					</span></span>
			</div></div>

		<div class="group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0"><div class="flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-['▶'] false"><span><span class="inline-block space-x-1 leading-5"><span><!-- HTML_TAG_START -->6. The 🤗 Tokenizers library<!-- HTML_TAG_END --></span>

					</span></span>
			</div></div>

		<div class="group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0"><div class="flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-['▶'] false"><span><span class="inline-block space-x-1 leading-5"><span><!-- HTML_TAG_START -->7. Main NLP tasks<!-- HTML_TAG_END --></span>

					</span></span>
			</div></div>

		<div class="group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0"><div class="flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-['▶'] false"><span><span class="inline-block space-x-1 leading-5"><span><!-- HTML_TAG_START -->8. How to ask for help<!-- HTML_TAG_END --></span>

					</span></span>
			</div></div>

		<div class="group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0"><div class="flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-['▶'] false"><span><span class="inline-block space-x-1 leading-5"><span><!-- HTML_TAG_START -->9. Building and sharing demos<!-- HTML_TAG_END --></span>
						<span class="ml-1 rounded bg-yellow-200 px-1 text-xs text-yellow-900 dark:bg-yellow-500">new</span>
					</span></span>
			</div></div>

		<div class="group flex cursor-pointer items-center pl-2 text-[0.8rem] font-semibold uppercase leading-9 hover:text-gray-700 dark:hover:text-gray-300 ml-0"><div class="flex after:absolute after:right-4 after:text-gray-500 group-hover:after:content-['▶'] false"><span><span class="inline-block space-x-1 leading-5"><span><!-- HTML_TAG_START -->Course Events<!-- HTML_TAG_END --></span>

					</span></span>
			</div></div>
		</nav></div></div></div>
		<div class="z-1 min-w-0 flex-1">
			<div class="px-6 pt-6 md:px-12 md:pt-16 md:pb-16"><div class="max-w-4xl mx-auto mb-10"><div class="relative overflow-hidden rounded-xl bg-gradient-to-br from-orange-300/10 py-5 px-4 ring-1 ring-orange-100/70 md:px-6 md:py-8"><img alt="Hugging Face's logo" class="absolute -right-6 -bottom-6 w-28 -rotate-45 md:hidden" src="/front/assets/huggingface_logo-noborder.svg">
		<div class="mb-2 text-2xl font-bold dark:text-gray-200 md:mb-0">Join the Hugging Face community</div>
		<p class="mb-4 text-lg text-gray-400 dark:text-gray-300 md:mb-8">and get access to the augmented documentation experience
		</p>
		<div class="mb-8 hidden space-y-4 md:block xl:flex xl:space-y-0 xl:space-x-6"><div class="flex items-center"><div class="mr-3 flex h-9 w-9 flex-none items-center justify-center rounded-lg bg-gradient-to-br from-indigo-100 to-indigo-100/20 dark:to-indigo-100"><svg class="text-indigo-400 group-hover:text-indigo-500" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 24 24"><path class="uim-quaternary" d="M20.23 7.24L12 12L3.77 7.24a1.98 1.98 0 0 1 .7-.71L11 2.76c.62-.35 1.38-.35 2 0l6.53 3.77c.29.173.531.418.7.71z" opacity=".25" fill="currentColor"></path><path class="uim-tertiary" d="M12 12v9.5a2.09 2.09 0 0 1-.91-.21L4.5 17.48a2.003 2.003 0 0 1-1-1.73v-7.5a2.06 2.06 0 0 1 .27-1.01L12 12z" opacity=".5" fill="currentColor"></path><path class="uim-primary" d="M20.5 8.25v7.5a2.003 2.003 0 0 1-1 1.73l-6.62 3.82c-.275.13-.576.198-.88.2V12l8.23-4.76c.175.308.268.656.27 1.01z" fill="currentColor"></path></svg></div>
				<div class="text-smd leading-tight text-gray-500 dark:text-gray-300 xl:max-w-[200px] 2xl:text-base">Collaborate on models, datasets and Spaces
				</div></div>
			<div class="flex items-center"><div class="mr-3 flex h-9 w-9 flex-none items-center justify-center rounded-lg bg-gradient-to-br from-orange-100 to-orange-100/20 dark:to-orange-50"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" class="text-xl text-yellow-400" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 24 24"><path d="M11 15H6l7-14v8h5l-7 14v-8z" fill="currentColor"></path></svg></div>
				<div class="text-smd leading-tight text-gray-500 dark:text-gray-300 xl:max-w-[200px] 2xl:text-base">Faster examples with accelerated inference
				</div></div>
			<div class="flex items-center"><div class="mr-3 flex h-9 w-9 flex-none items-center justify-center rounded-lg bg-gradient-to-br from-gray-500/10 to-gray-500/5"><svg class="text-gray-400" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M14.9804 3C14.9217 3.0002 14.8631 3.00555 14.8054 3.016C11.622 3.58252 8.76073 5.30669 6.77248 7.85653C4.78422 10.4064 3.80955 13.6016 4.03612 16.8271C4.26268 20.0525 5.67447 23.0801 7.99967 25.327C10.3249 27.5738 13.3991 28.8811 16.6304 28.997C16.7944 29.003 16.9584 28.997 17.1204 28.997C19.2193 28.9984 21.2877 28.4943 23.1507 27.5274C25.0137 26.5605 26.6164 25.1592 27.8234 23.442C27.9212 23.294 27.9783 23.1229 27.9889 22.9458C27.9995 22.7687 27.9633 22.592 27.884 22.4333C27.8046 22.2747 27.6848 22.1397 27.5367 22.0421C27.3887 21.9444 27.2175 21.8875 27.0404 21.877C25.0426 21.7017 23.112 21.0693 21.3976 20.0288C19.6832 18.9884 18.231 17.5676 17.1533 15.8764C16.0756 14.1852 15.4011 12.2688 15.1822 10.2754C14.9632 8.28193 15.2055 6.26484 15.8904 4.38C15.9486 4.22913 15.97 4.06652 15.9527 3.90572C15.9354 3.74492 15.8799 3.59059 15.7909 3.45557C15.7019 3.32055 15.5819 3.20877 15.4409 3.12952C15.2999 3.05028 15.142 3.00587 14.9804 3Z" fill="currentColor"></path></svg></div>
				<div class="text-smd leading-tight text-gray-500 dark:text-gray-300 xl:max-w-[200px] 2xl:text-base">Switch between documentation themes
				</div></div></div>
		<div class="flex items-center space-x-2.5"><a href="/join"><button class="rounded-lg bg-white bg-gradient-to-br from-gray-100/20 to-gray-200/60 py-1.5 px-5 font-semibold text-gray-700 shadow-sm ring-1 ring-gray-300/60 hover:to-gray-100/70 hover:ring-gray-300/30 active:shadow-inner">Sign Up</button></a>
			<p class="text-gray-500 dark:text-gray-300">to get started</p></div></div></div>
				<div class="prose-doc prose relative mx-auto max-w-4xl break-words"><!-- HTML_TAG_START -->	<link rel="modulepreload" href="/docs/course/main/en/_app/assets/pages/__layout.svelte-hf-doc-builder.css">
	<link rel="modulepreload" href="/docs/course/main/en/_app/start-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/course/main/en/_app/chunks/vendor-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/course/main/en/_app/chunks/paths-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/course/main/en/_app/pages/__layout.svelte-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/course/main/en/_app/pages/chapter1/4.mdx-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/course/main/en/_app/chunks/Youtube-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/course/main/en/_app/chunks/IconCopyLink-hf-doc-builder.js">
	<link rel="modulepreload" href="/docs/course/main/en/_app/chunks/CourseFloatingBanner-hf-doc-builder.js">





<h1 class="relative group"><a id="how-do-transformers-work" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#how-do-transformers-work"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>How do Transformers work?
	</span></h1>



<div class="flex space-x-1 absolute z-10 right-0 top-0"><a href="https://discuss.huggingface.co/t/chapter-1-questions" target="_blank"><img alt="Ask a Question" class="!m-0" src="https://img.shields.io/badge/Ask%20a%20question-ffcb4c.svg?logo=data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgLTEgMTA0IDEwNiI+PGRlZnM+PHN0eWxlPi5jbHMtMXtmaWxsOiMyMzFmMjA7fS5jbHMtMntmaWxsOiNmZmY5YWU7fS5jbHMtM3tmaWxsOiMwMGFlZWY7fS5jbHMtNHtmaWxsOiMwMGE5NGY7fS5jbHMtNXtmaWxsOiNmMTVkMjI7fS5jbHMtNntmaWxsOiNlMzFiMjM7fTwvc3R5bGU+PC9kZWZzPjx0aXRsZT5EaXNjb3Vyc2VfbG9nbzwvdGl0bGU+PGcgaWQ9IkxheWVyXzIiPjxnIGlkPSJMYXllcl8zIj48cGF0aCBjbGFzcz0iY2xzLTEiIGQ9Ik01MS44NywwQzIzLjcxLDAsMCwyMi44MywwLDUxYzAsLjkxLDAsNTIuODEsMCw1Mi44MWw1MS44Ni0uMDVjMjguMTYsMCw1MS0yMy43MSw1MS01MS44N1M4MCwwLDUxLjg3LDBaIi8+PHBhdGggY2xhc3M9ImNscy0yIiBkPSJNNTIuMzcsMTkuNzRBMzEuNjIsMzEuNjIsMCwwLDAsMjQuNTgsNjYuNDFsLTUuNzIsMTguNEwzOS40LDgwLjE3YTMxLjYxLDMxLjYxLDAsMSwwLDEzLTYwLjQzWiIvPjxwYXRoIGNsYXNzPSJjbHMtMyIgZD0iTTc3LjQ1LDMyLjEyYTMxLjYsMzEuNiwwLDAsMS0zOC4wNSw0OEwxOC44Niw4NC44MmwyMC45MS0yLjQ3QTMxLjYsMzEuNiwwLDAsMCw3Ny40NSwzMi4xMloiLz48cGF0aCBjbGFzcz0iY2xzLTQiIGQ9Ik03MS42MywyNi4yOUEzMS42LDMxLjYsMCwwLDEsMzguOCw3OEwxOC44Niw4NC44MiwzOS40LDgwLjE3QTMxLjYsMzEuNiwwLDAsMCw3MS42MywyNi4yOVoiLz48cGF0aCBjbGFzcz0iY2xzLTUiIGQ9Ik0yNi40Nyw2Ny4xMWEzMS42MSwzMS42MSwwLDAsMSw1MS0zNUEzMS42MSwzMS42MSwwLDAsMCwyNC41OCw2Ni40MWwtNS43MiwxOC40WiIvPjxwYXRoIGNsYXNzPSJjbHMtNiIgZD0iTTI0LjU4LDY2LjQxQTMxLjYxLDMxLjYxLDAsMCwxLDcxLjYzLDI2LjI5YTMxLjYxLDMxLjYxLDAsMCwwLTQ5LDM5LjYzbC0zLjc2LDE4LjlaIi8+PC9nPjwvZz48L3N2Zz4="></a>

	</div>
<p>In this section, we will take a high-level look at the architecture of Transformer models.</p>
<h2 class="relative group"><a id="a-bit-of-transformer-history" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#a-bit-of-transformer-history"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>A bit of Transformer history
	</span></h2>

<p>Here are some reference points in the (short) history of Transformer models:</p>
<div class="flex justify-center"><img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/transformers_chrono.svg" alt="A brief chronology of Transformers models.">
<img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/transformers_chrono-dark.svg" alt="A brief chronology of Transformers models."></div>
<p>The <a href="https://arxiv.org/abs/1706.03762" rel="nofollow">Transformer architecture</a> was introduced in June 2017. The focus of the original research was on translation tasks. This was followed by the introduction of several influential models, including:</p>
<ul><li><p><strong>June 2018</strong>: <a href="https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf" rel="nofollow">GPT</a>, the first pretrained Transformer model, used for fine-tuning on various NLP tasks and obtained state-of-the-art results</p></li>
<li><p><strong>October 2018</strong>: <a href="https://arxiv.org/abs/1810.04805" rel="nofollow">BERT</a>, another large pretrained model, this one designed to produce better summaries of sentences (more on this in the next chapter!)</p></li>
<li><p><strong>February 2019</strong>: <a href="https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf" rel="nofollow">GPT-2</a>, an improved (and bigger) version of GPT that was not immediately publicly released due to ethical concerns</p></li>
<li><p><strong>October 2019</strong>: <a href="https://arxiv.org/abs/1910.01108" rel="nofollow">DistilBERT</a>, a distilled version of BERT that is 60% faster, 40% lighter in memory, and still retains 97% of BERT’s performance</p></li>
<li><p><strong>October 2019</strong>: <a href="https://arxiv.org/abs/1910.13461" rel="nofollow">BART</a> and <a href="https://arxiv.org/abs/1910.10683" rel="nofollow">T5</a>, two large pretrained models using the same architecture as the original Transformer model (the first to do so)</p></li>
<li><p><strong>May 2020</strong>, <a href="https://arxiv.org/abs/2005.14165" rel="nofollow">GPT-3</a>, an even bigger version of GPT-2 that is able to perform well on a variety of tasks without the need for fine-tuning (called <em>zero-shot learning</em>)</p></li></ul>
<p>This list is far from comprehensive, and is just meant to highlight a few of the different kinds of Transformer models. Broadly, they can be grouped into three categories:</p>
<ul><li>GPT-like (also called <em>auto-regressive</em> Transformer models)</li>
<li>BERT-like (also called <em>auto-encoding</em> Transformer models) </li>
<li>BART/T5-like (also called <em>sequence-to-sequence</em> Transformer models)</li></ul>
<p>We will dive into these families in more depth later on.</p>
<h2 class="relative group"><a id="transformers-are-language-models" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#transformers-are-language-models"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Transformers are language models
	</span></h2>

<p>All the Transformer models mentioned above (GPT, BERT, BART, T5, etc.) have been trained as <em>language models</em>. This means they have been trained on large amounts of raw text in a self-supervised fashion. Self-supervised learning is a type of training in which the objective is automatically computed from the inputs of the model. That means that humans are not needed to label the data!</p>
<p>This type of model develops a statistical understanding of the language it has been trained on, but it’s not very useful for specific practical tasks. Because of this, the general pretrained model then goes through a process called <em>transfer learning</em>. During this process, the model is fine-tuned in a supervised way — that is, using human-annotated labels — on a given task.</p>
<p>An example of a task is predicting the next word in a sentence having read the <em>n</em> previous words. This is called <em>causal language modeling</em> because the output depends on the past and present inputs, but not the future ones.</p>
<div class="flex justify-center"><img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/causal_modeling.svg" alt="Example of causal language modeling in which the next word from a sentence is predicted.">
<img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/causal_modeling-dark.svg" alt="Example of causal language modeling in which the next word from a sentence is predicted."></div>
<p>Another example is <em>masked language modeling</em>, in which the model predicts a masked word in the sentence.</p>
<div class="flex justify-center"><img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/masked_modeling.svg" alt="Example of masked language modeling in which a masked word from a sentence is predicted.">
<img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/masked_modeling-dark.svg" alt="Example of masked language modeling in which a masked word from a sentence is predicted."></div>
<h2 class="relative group"><a id="transformers-are-big-models" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#transformers-are-big-models"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Transformers are big models
	</span></h2>

<p>Apart from a few outliers (like DistilBERT), the general strategy to achieve better performance is by increasing the models’ sizes as well as the amount of data they are pretrained on.</p>
<div class="flex justify-center"><img src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/model_parameters.png" alt="Number of parameters of recent Transformers models" width="90%"></div>
<p>Unfortunately, training a model, especially a large one, requires a large amount of data. This becomes very costly in terms of time and compute resources. It even translates to environmental impact, as can be seen in the following graph.</p>
<div class="flex justify-center"><img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/carbon_footprint.svg" alt="The carbon footprint of a large language model.">
<img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/carbon_footprint-dark.svg" alt="The carbon footprint of a large language model."></div>
<iframe class="w-full xl:w-4/6 h-80" src="https://www.youtube-nocookie.com/embed/ftWlj4FBHTg" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p>And this is showing a project for a (very big) model led by a team consciously trying to reduce the environmental impact of pretraining. The footprint of running lots of trials to get the best hyperparameters would be even higher.</p>
<p>Imagine if each time a research team, a student organization, or a company wanted to train a model, it did so from scratch. This would lead to huge, unnecessary global costs!</p>
<p>This is why sharing language models is paramount: sharing the trained weights and building on top of already trained weights reduces the overall compute cost and carbon footprint of the community.</p>
<p>By the way, you can evaluate the carbon footprint of your models’ training through several tools. For example <a href="https://mlco2.github.io/impact/" rel="nofollow">ML CO2 Impact</a> or <a href="https://codecarbon.io/" rel="nofollow">Code Carbon</a> which is integrated in 🤗 Transformers. To learn more about this, you can read this <a href="https://huggingface.co/blog/carbon-emissions-on-the-hub" rel="nofollow">blog post</a> which will show you how to generate an <code>emissions.csv</code> file with an estimate of the footprint of your training, as well as the <a href="https://huggingface.co/docs/hub/model-cards-co2" rel="nofollow">documentation</a> of 🤗 Transformers addressing this topic.</p>
<h2 class="relative group"><a id="transfer-learning" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#transfer-learning"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Transfer Learning
	</span></h2>

<iframe class="w-full xl:w-4/6 h-80" src="https://www.youtube-nocookie.com/embed/BqqfQnyjmgg" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p><em>Pretraining</em> is the act of training a model from scratch: the weights are randomly initialized, and the training starts without any prior knowledge.</p>
<div class="flex justify-center"><img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/pretraining.svg" alt="The pretraining of a language model is costly in both time and money.">
<img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/pretraining-dark.svg" alt="The pretraining of a language model is costly in both time and money."></div>
<p>This pretraining is usually done on very large amounts of data. Therefore, it requires a very large corpus of data, and training can take up to several weeks.</p>
<p><em>Fine-tuning</em>, on the other hand, is the training done <strong>after</strong> a model has been pretrained. To perform fine-tuning, you first acquire a pretrained language model, then perform additional training with a dataset specific to your task. Wait — why not simply train directly for the final task? There are a couple of reasons:</p>
<ul><li>The pretrained model was already trained on a dataset that has some similarities with the fine-tuning dataset. The fine-tuning process is thus able to take advantage of knowledge acquired by the initial model during pretraining (for instance, with NLP problems, the pretrained model will have some kind of statistical understanding of the language you are using for your task). </li>
<li>Since the pretrained model was already trained on lots of data, the fine-tuning requires way less data to get decent results.</li>
<li>For the same reason, the amount of time and resources needed to get good results are much lower.</li></ul>
<p>For example, one could leverage a pretrained model trained on the English language and then fine-tune it on an arXiv corpus, resulting in a science/research-based model. The fine-tuning will only require a limited amount of data: the knowledge the pretrained model has acquired is “transferred,” hence the term <em>transfer learning</em>.</p>
<div class="flex justify-center"><img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/finetuning.svg" alt="The fine-tuning of a language model is cheaper than pretraining in both time and money.">
<img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/finetuning-dark.svg" alt="The fine-tuning of a language model is cheaper than pretraining in both time and money."></div>
<p>Fine-tuning a model therefore has lower time, data, financial, and environmental costs. It is also quicker and easier to iterate over different fine-tuning schemes, as the training is less constraining than a full pretraining.</p>
<p>This process will also achieve better results than training from scratch (unless you have lots of data), which is why you should always try to leverage a pretrained model — one as close as possible to the task you have at hand — and fine-tune it.</p>
<h2 class="relative group"><a id="general-architecture" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#general-architecture"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>General architecture
	</span></h2>

<p>In this section, we’ll go over the general architecture of the Transformer model. Don’t worry if you don’t understand some of the concepts; there are detailed sections later covering each of the components.</p>
<iframe class="w-full xl:w-4/6 h-80" src="https://www.youtube-nocookie.com/embed/H39Z_720T5s" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<h2 class="relative group"><a id="introduction" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#introduction"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Introduction
	</span></h2>

<p>The model is primarily composed of two blocks:</p>
<ul><li><strong>Encoder (left)</strong>: The encoder receives an input and builds a representation of it (its features). This means that the model is optimized to acquire understanding from the input.</li>
<li><strong>Decoder (right)</strong>: The decoder uses the encoder’s representation (features) along with other inputs to generate a target sequence. This means that the model is optimized for generating outputs.</li></ul>
<div class="flex justify-center"><img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/transformers_blocks.svg" alt="Architecture of a Transformers models">
<img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/transformers_blocks-dark.svg" alt="Architecture of a Transformers models"></div>
<p>Each of these parts can be used independently, depending on the task: </p>
<ul><li><strong>Encoder-only models</strong>: Good for tasks that require understanding of the input, such as sentence classification and named entity recognition.</li>
<li><strong>Decoder-only models</strong>: Good for generative tasks such as text generation.</li>
<li><strong>Encoder-decoder models</strong> or <strong>sequence-to-sequence models</strong>: Good for generative tasks that require an input, such as translation or summarization.</li></ul>
<p>We will dive into those architectures independently in later sections.</p>
<h2 class="relative group"><a id="attention-layers" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#attention-layers"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Attention layers
	</span></h2>

<p>A key feature of Transformer models is that they are built with special layers called <em>attention layers</em>. In fact, the title of the paper introducing the Transformer architecture was <a href="https://arxiv.org/abs/1706.03762" rel="nofollow">“Attention Is All You Need”</a>! We will explore the details of attention layers later in the course; for now, all you need to know is that this layer will tell the model to pay specific attention to certain words in the sentence you passed it (and more or less ignore the others) when dealing with the representation of each word.</p>
<p>To put this into context, consider the task of translating text from English to French. Given the input “You like this course”, a translation model will need to also attend to the adjacent word “You” to get the proper translation for the word “like”, because in French the verb “like” is conjugated differently depending on the subject. The rest of the sentence, however, is not useful for the translation of that word. In the same vein, when translating “this” the model will also need to pay attention to the word “course”, because “this” translates differently depending on whether the associated noun is masculine or feminine. Again, the other words in the sentence will not matter for the translation of “this”. With more complex sentences (and more complex grammar rules), the model would need to pay special attention to words that might appear farther away in the sentence to properly translate each word.</p>
<p>The same concept applies to any task associated with natural language: a word by itself has a meaning, but that meaning is deeply affected by the context, which can be any other word (or words) before or after the word being studied.</p>
<p>Now that you have an idea of what attention layers are all about, let’s take a closer look at the Transformer architecture.</p>
<h2 class="relative group"><a id="the-original-architecture" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#the-original-architecture"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>The original architecture
	</span></h2>

<p>The Transformer architecture was originally designed for translation. During training, the encoder receives inputs (sentences) in a certain language, while the decoder receives the same sentences in the desired target language. In the encoder, the attention layers can use all the words in a sentence (since, as we just saw, the translation of a given word can be dependent on what is after as well as before it in the sentence). The decoder, however, works sequentially and can only pay attention to the words in the sentence that it has already translated (so, only the words before the word currently being generated). For example, when we have predicted the first three words of the translated target, we give them to the decoder  which then uses all the inputs of the encoder to try to predict the fourth word.</p>
<p>To speed things up during training (when the model has access to target sentences), the decoder is fed the whole target, but it is not allowed to use future words (if it had access to the word at position 2 when trying to predict the word at position 2, the problem would not be very hard!). For instance, when trying to predict the fourth word, the attention layer will only have access to the words in positions 1 to 3.</p>
<p>The original Transformer architecture looked like this, with the encoder on the left and the decoder on the right:</p>
<div class="flex justify-center"><img class="block dark:hidden" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/transformers.svg" alt="Architecture of a Transformers models">
<img class="hidden dark:block" src="https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter1/transformers-dark.svg" alt="Architecture of a Transformers models"></div>
<p>Note that the first attention layer in a decoder block pays attention to all (past) inputs to the decoder, but the second attention layer uses the output of the encoder. It can thus access the whole input sentence to best predict the current word. This is very useful as different languages can have grammatical rules that put the words in different orders, or some context provided later in the sentence may be helpful to determine the best translation of a given word.</p>
<p>The <em>attention mask</em> can also be used in the encoder/decoder to prevent the model from paying attention to some special words — for instance, the special padding word used to make all the inputs the same length when batching together sentences.</p>
<h2 class="relative group"><a id="architecture-vs-checkpoints" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#architecture-vs-checkpoints"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a>
	<span>Architectures vs. checkpoints
	</span></h2>

<p>As we dive into Transformer models in this course, you’ll see mentions of <em>architectures</em> and <em>checkpoints</em> as well as <em>models</em>. These terms all have slightly different meanings: </p>
<ul><li><strong>Architecture</strong>: This is the skeleton of the model — the definition of each layer and each operation that happens within the model. </li>
<li><strong>Checkpoints</strong>: These are the weights that will be loaded in a given architecture.</li>
<li><strong>Model</strong>: This is an umbrella term that isn’t as precise as “architecture” or “checkpoint”: it can mean both. This course will specify <em>architecture</em> or <em>checkpoint</em> when it matters to reduce ambiguity.</li></ul>
<p>For example, BERT is an architecture while <code>bert-base-cased</code>, a set of weights trained by the Google team for the first release of BERT, is a checkpoint. However, one can say “the BERT model” and “the <code>bert-base-cased</code> model.”</p>


		<script type="module" data-hydrate="182czzn">
		import { start } from "/docs/course/main/en/_app/start-hf-doc-builder.js";
		start({
			target: document.querySelector('[data-hydrate="182czzn"]').parentNode,
			paths: {"base":"/docs/course/main/en","assets":"/docs/course/main/en"},
			session: {},
			route: false,
			spa: false,
			trailing_slash: "never",
			hydrate: {
				status: 200,
				error: null,
				nodes: [
					import("/docs/course/main/en/_app/pages/__layout.svelte-hf-doc-builder.js"),
						import("/docs/course/main/en/_app/pages/chapter1/4.mdx-hf-doc-builder.js")
				],
				params: {}
			}
		});
	</script>
<!-- HTML_TAG_END --></div>
				<div class="mx-auto mt-16 flex max-w-4xl items-center pb-8 font-sans font-medium leading-6 xl:mt-32"><a href="/learn/nlp-course/chapter1/3?fw=pt" class="mr-8 flex transform items-center text-gray-600 transition-all hover:-translate-x-px hover:text-gray-900 dark:hover:text-gray-300"><span class="mr-2 translate-y-px">←</span>Transformers, what can they do?</a>
					<a href="/learn/nlp-course/chapter1/5?fw=pt" class="ml-auto flex transform items-center text-right text-gray-600 transition-all hover:translate-x-px hover:text-gray-900 dark:hover:text-gray-300">Encoder models<span class="ml-2 translate-y-px">→</span></a></div></div></div>
		<div class="sticky top-0 self-start"><div class="SVELTE_HYDRATER contents" data-props="{&quot;chapter&quot;:{&quot;title&quot;:&quot;How do Transformers work?&quot;,&quot;isExpanded&quot;:false,&quot;id&quot;:&quot;how-do-transformers-work&quot;,&quot;url&quot;:&quot;#how-do-transformers-work&quot;,&quot;sections&quot;:[{&quot;title&quot;:&quot;A bit of Transformer history&quot;,&quot;id&quot;:&quot;a-bit-of-transformer-history&quot;,&quot;url&quot;:&quot;#a-bit-of-transformer-history&quot;},{&quot;title&quot;:&quot;Transformers are language models&quot;,&quot;id&quot;:&quot;transformers-are-language-models&quot;,&quot;url&quot;:&quot;#transformers-are-language-models&quot;},{&quot;title&quot;:&quot;Transformers are big models&quot;,&quot;id&quot;:&quot;transformers-are-big-models&quot;,&quot;url&quot;:&quot;#transformers-are-big-models&quot;},{&quot;title&quot;:&quot;Transfer Learning&quot;,&quot;id&quot;:&quot;transfer-learning&quot;,&quot;url&quot;:&quot;#transfer-learning&quot;},{&quot;title&quot;:&quot;General architecture&quot;,&quot;id&quot;:&quot;general-architecture&quot;,&quot;url&quot;:&quot;#general-architecture&quot;},{&quot;title&quot;:&quot;Introduction&quot;,&quot;id&quot;:&quot;introduction&quot;,&quot;url&quot;:&quot;#introduction&quot;},{&quot;title&quot;:&quot;Attention layers&quot;,&quot;id&quot;:&quot;attention-layers&quot;,&quot;url&quot;:&quot;#attention-layers&quot;},{&quot;title&quot;:&quot;The original architecture&quot;,&quot;id&quot;:&quot;the-original-architecture&quot;,&quot;url&quot;:&quot;#the-original-architecture&quot;},{&quot;title&quot;:&quot;Architectures vs. checkpoints&quot;,&quot;id&quot;:&quot;architecture-vs-checkpoints&quot;,&quot;url&quot;:&quot;#architecture-vs-checkpoints&quot;}]}}" data-target="SubSideMenu">

<nav class="hidden h-screen w-[270px] flex-none flex-col space-y-3 overflow-y-auto break-words border-l pt-24 pl-6 pr-10 pb-16 text-sm lg:flex 2xl:w-[305px]"><a href="#how-do-transformers-work" class=" text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300" id="nav-how-do-transformers-work"><!-- HTML_TAG_START --><wbr>How do <wbr>Transformers work?<!-- HTML_TAG_END --></a>
	<a href="#a-bit-of-transformer-history" class="pl-4 text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300" id="nav-a-bit-of-transformer-history"><!-- HTML_TAG_START --><wbr>A bit of <wbr>Transformer history<!-- HTML_TAG_END --></a>
			<a href="#transformers-are-language-models" class="pl-4 text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300" id="nav-transformers-are-language-models"><!-- HTML_TAG_START --><wbr>Transformers are language models<!-- HTML_TAG_END --></a>
			<a href="#transformers-are-big-models" class="pl-4 text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300" id="nav-transformers-are-big-models"><!-- HTML_TAG_START --><wbr>Transformers are big models<!-- HTML_TAG_END --></a>
			<a href="#transfer-learning" class="pl-4 text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300" id="nav-transfer-learning"><!-- HTML_TAG_START --><wbr>Transfer <wbr>Learning<!-- HTML_TAG_END --></a>
			<a href="#general-architecture" class="pl-4 text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300" id="nav-general-architecture"><!-- HTML_TAG_START --><wbr>General architecture<!-- HTML_TAG_END --></a>
			<a href="#introduction" class="pl-4 text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300" id="nav-introduction"><!-- HTML_TAG_START --><wbr>Introduction<!-- HTML_TAG_END --></a>
			<a href="#attention-layers" class="pl-4 text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300" id="nav-attention-layers"><!-- HTML_TAG_START --><wbr>Attention layers<!-- HTML_TAG_END --></a>
			<a href="#the-original-architecture" class="pl-4 text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300" id="nav-the-original-architecture"><!-- HTML_TAG_START --><wbr>The original architecture<!-- HTML_TAG_END --></a>
			<a href="#architecture-vs-checkpoints" class="pl-4 text-gray-400 transform hover:translate-x-px hover:text-gray-700 dark:hover:text-gray-300" id="nav-architecture-vs-checkpoints"><!-- HTML_TAG_START --><wbr>Architectures vs. checkpoints<!-- HTML_TAG_END --></a>
			</nav></div></div></div>
	<div id="doc-footer"></div></main>
	</div>

		<script>
			import("/front/build/kube-3d31136/index.js");
			window.moonSha = "kube-3d31136/";
			window.hubConfig = JSON.parse(`{"features":{"signupDisabled":false,"awsMarketplace":false},"sshGitUrl":"git@hf.co","moonHttpUrl":"https://huggingface.co","captchaApiKey":"bd5f2066-93dc-4bdd-a64b-a24646ca3859","stripePublicKey":"pk_live_x2tdjFXBCvXo2FFmMybezpeM00J6gPCAAc","environment":"production","userAgent":"HuggingFace (production)"}`);
		</script>

		<!-- Stripe -->
		<script>
			if (["hf.co", "huggingface.co"].includes(window.location.hostname)) {
				const script = document.createElement("script");
				script.src = "https://js.stripe.com/v3/";
				script.async = true;
				document.head.appendChild(script);
			}
		</script>

		<!-- Google analytics v4 -->
		<script>
			if (["hf.co", "huggingface.co"].includes(window.location.hostname)) {
				const script = document.createElement("script");
				script.src = "https://www.googletagmanager.com/gtag/js?id=G-8Q63TH4CSL";
				script.async = true;
				document.head.appendChild(script);

				window.dataLayer = window.dataLayer || [];
				function gtag() {
					if (window.dataLayer !== undefined) {
						window.dataLayer.push(arguments);
					}
				}
				gtag("js", new Date());
				gtag("config", "G-8Q63TH4CSL", { page_path: "/learn/nlp-course/chapter1/4" });
				/// ^ See https://developers.google.com/analytics/devguides/collection/gtagjs/pages
				gtag("consent", "default", { ad_storage: "denied", analytics_storage: "denied" });
				/// ^ See https://developers.google.com/tag-platform/gtagjs/reference#consent
				/// TODO: ask the user for their consent and update this with gtag('consent', 'update')
			}
		</script>

		<!-- Google Analytics v3 (deprecated) -->
		<script>
			if (["hf.co", "huggingface.co"].includes(window.location.hostname)) {
				(function (i, s, o, g, r, a, m) {
					i["GoogleAnalyticsObject"] = r;
					(i[r] =
						i[r] ||
						function () {
							(i[r].q = i[r].q || []).push(arguments);
						}),
						(i[r].l = 1 * new Date());
					(a = s.createElement(o)), (m = s.getElementsByTagName(o)[0]);
					a.async = 1;
					a.src = g;
					m.parentNode.insertBefore(a, m);
				})(window, document, "script", "https://www.google-analytics.com/analytics.js", "ganalytics");
				ganalytics("create", "UA-83738774-2", "auto");
				ganalytics("send", "pageview", "/learn/nlp-course/chapter1/4");
			}
		</script>
	</body>
</html>
